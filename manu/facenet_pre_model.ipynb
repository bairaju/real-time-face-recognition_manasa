{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model built\n",
      "weights loaded\n",
      "employee representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "from os import listdir\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "from inception_resnet_v1 import *\n",
    "model = InceptionResNetV1()\n",
    "print(\"model built\")\n",
    "model.load_weights('facenet_weights.h5')\n",
    "print(\"weights loaded\")\n",
    "\n",
    "#------------------------\n",
    "\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance\n",
    "\n",
    "#------------------------\n",
    "\n",
    "threshold = 21 #tuned threshold for l2 disabled euclidean distance\n",
    "\n",
    "#------------------------\t\n",
    "\n",
    "#put your employee pictures in this path as name_of_employee.jpg\n",
    "employee_pictures = \"deepika/\"\n",
    "\n",
    "employees = dict()\n",
    "\n",
    "for file in listdir(employee_pictures):\n",
    "\temployee, extension = file.split(\".\")\n",
    "\timg = preprocess_image('deepika/%s.jpg' % (employee))\n",
    "\trepresentation = model.predict(img)[0,:]\n",
    "\t\n",
    "\temployees[employee] = representation\n",
    "\t\n",
    "print(\"employee representations retrieved successfully\")\n",
    "\n",
    "#------------------------\n",
    "\n",
    "cap = cv2.VideoCapture(0) #webcam\n",
    "\n",
    "while(True):\n",
    "\tret, img = cap.read()\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #discard small detected faces\n",
    "\t\t\tcv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\tdetected_face = cv2.resize(detected_face, (160, 160)) #resize to 224x224\n",
    "\t\t\t\n",
    "\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\t#employee dictionary is using preprocess_image and it normalizes in scale of [-1, +1]\n",
    "\t\t\timg_pixels /= 127.5\n",
    "\t\t\timg_pixels -= 1\n",
    "\t\t\t\n",
    "\t\t\tcaptured_representation = model.predict(img_pixels)[0,:]\n",
    "\t\t\t\n",
    "\t\t\tdistances = []\n",
    "\t\t\t\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tsource_representation = employees[i]\n",
    "\t\t\t\t\n",
    "\t\t\t\tdistance = findEuclideanDistance(captured_representation, source_representation)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#print(employee_name,\": \",distance)\n",
    "\t\t\t\tdistances.append(distance)\n",
    "\t\t\t\n",
    "\t\t\tlabel_name = 'unknown'\n",
    "\t\t\tindex = 0\n",
    "\t\t\tfor i in employees:\n",
    "\t\t\t\temployee_name = i\n",
    "\t\t\t\tif index == np.argmin(distances):\n",
    "\t\t\t\t\tif distances[index] <= threshold:\n",
    "\t\t\t\t\t\t#print(\"detected: \",employee_name)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#label_name = \"%s (distance: %s)\" % (employee_name, str(round(distance,2)))\n",
    "\t\t\t\t\t\tsimilarity = 100 + (20 - distance)\n",
    "\t\t\t\t\t\tif similarity > 99.99: similarity = 99.99\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tlabel_name = \"%s (%s%s)\" % (employee_name, str(round(similarity,2)), '%')\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\n",
    "\t\t\t\tindex = index + 1\n",
    "\t\t\t\n",
    "\t\t\tcv2.putText(img, label_name, (int(x+w+15), int(y-64)), cv2.FONT_HERSHEY_SIMPLEX, 1, (67,67,67), 2)\n",
    "\t\t\t\t\t\n",
    "\t\t\t#connect face and text\n",
    "\t\t\tcv2.line(img,(x+w, y-64),(x+w-25, y-64),(67,67,67),1)\n",
    "\t\t\tcv2.line(img,(int(x+w/2),y),(x+w-25,y-64),(67,67,67),1)\n",
    "\t\t\t\n",
    "\tcv2.imshow('img',img)\n",
    "\t\n",
    "\tif cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "\t\tbreak\n",
    "\t\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
